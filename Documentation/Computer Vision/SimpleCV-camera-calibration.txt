# SimpleCV camera calibration

# For easier image processing, we will want to correct for certain camera and lighting characteristics:
#  - lens distortion (so that straight lines appear straight on the image)
#  - white balance (variations in lighting, and probably want to fix the camera WB setting as well so it doesn't vary)

# Some of these apparently can't be set via SimpleCV, so will have to be set using an external command, possibly while SimpleCV is running, e.g.
# guvcview
# or
# uvcdynctrl -c -v


# SimpleCV provides a fairly easy way to determine camera lens distortion using a printed checkerboard pattern.

Camera.calibrate()
	# or run calibrate.py
Camera.getCameraMatrix()
Camera.getImageUndistort()
	# getImage() + undistort()

Camera.live()


Printed calibration grid, ran Calibrate.py...


defaultDistortion.xml

<<
<?xml version="1.0"?>
<opencv_storage>
<defaultDistortion type_id="opencv-matrix">
  <rows>5</rows>
  <cols>1</cols>
  <dt>f</dt>
  <data>
    6.69435692e+00 -8.86911011e+02 1.75753683e-02 -3.21384780e-02
    -4.43411350e+00</data></defaultDistortion>
</opencv_storage>
>>

defaultIntrinsic.xml

<<
<?xml version="1.0"?>
<opencv_storage>
<defaultIntrinsic type_id="opencv-matrix">
  <rows>3</rows>
  <cols>3</cols>
  <dt>f</dt>
  <data>
    7.19129883e+03 0. 3.57125641e+02 0. 1.92430469e+04 3.73752777e+02 0.
    0. 1.</data></defaultIntrinsic>
</opencv_storage>
>>

# Test it:

# simplecv
camera=SimpleCV.Camera()
camera.loadCalibration('default')
camera.getCameraMatrix()
camera.live()


image_raw = camera.getImage()
image_cal = camera.getImageUndistort()

# Well, it seems to work...and actually look too far off the raw image. Perhaps these Logitech cameras are pretty good already (or do some correction internally).

while True:
	camera.getImageUndistort().show()


--

OK, so how do we control the camera exposure setting?  We want to minimise blurring for easier image analysis.

Suggested capture settings:
	Resolution: 320 x 240 or even 160 x 120
	Frame rate: 5 or maybe 10 FPS (SimpleCV on the Pi probably can't do more than about 5 FPS when processing)
	Image format: RGB3
	White balance: fixed at ~5200/6000/6500? Do WB correction in software? Under indoor night-time lighting, a WB of about 3000 looks reasonable.
	Sharpness: 0
	Exposure: manual, 100
	Gain: 200 (adjust according to conditions)
	Focus: manual, 0..50 (try ~30 for soccer field use)

Will need an image calibration routine for the event, namely for setting:
	White balance
	Gain (possibly trading off with exposure)

Not sure if we can actually control all of these via SimpleCV's Camera interface...
Camera.getAllProperties()

{'brightness': 0.501960813999176,
 'contrast': 0.501960813999176,
 'exposure': -1.0,
 'gain': 0.7843137383460999,
 'height': 480.0,
 'hue': 0.0,
 'saturation': 0.501960813999176,
 'width': 640.0}


camera = Camera(prop_set={'width':320, 'height':240})

--

# Colour correction (white balance)

# http://www.cambridgeincolour.com/tutorials/white-balance.htm

# Manual (sample point based) white balance correction...

Image.applyHLSCurve()
Image.applyIntensityCurve()
Image.applyRGBCurve()


OK, here's a supposed-to-be-grey sample point:
coord: (285,205), color: (141.0, 146.0, 160.0)


grey=(141.0 + 146.0 + 160.0) / 3.0

# Ah, note that SimpleCV imports numpy, but as np.

grey_sample = (141.0, 146.0, 160.0)

grey=np.mean(grey_sample)

r_corr = grey / 141.0
g_corr = grey / 146.0
b_corr = grey / 160.0

# Oh, we don't even need those coefficients: just plug the raw values into the ColorCurve() constructor:

r_curve = SimpleCV.ColorCurve([[0,0], [141, 255]])
g_curve = SimpleCV.ColorCurve([[0,0], [146, 255]])
b_curve = SimpleCV.ColorCurve([[0,0], [160, 255]])

# Oh, right, these are spline-based so need at least 4 points defined...

# OK, what if we split to R,G,B and just adjust the brightness, then recombine...


image.isBGR() / image.getColorSpace()
b,g,r=image.splitChannels()

r = r * r_corr
g = g * g_corr
b = b * b_corr

#image=Image.mergeChannels(r,g,b)

# FFS, mergeChannels() expects four arguments?  What's the first one even used for?

Image.mergeChannels(r,b,g,r).show()

# So, to correct for white balance based on a sample grey point:

def wb(image,grey_sample):
	grey=np.mean(grey_sample)
	r_corr = grey / grey_sample[0]
	g_corr = grey / grey_sample[1]
	b_corr = grey / grey_sample[2]
	print('r_corr=' + str(r_corr) + ', g_corr=' + str(g_corr) + ', b_corr=' + str(b_corr))
	r,g,b=image.splitChannels()
	r = r * float(r_corr)
	g = g * float(g_corr)
	b = b * float(b_corr)
	return Image.mergeChannels(r,r,g,b)

# Test it:
camera.live()
# coord: (225,264), color: (158.0, 164.0, 184.0)
x=225
y=264
grey_sample=(158.0, 164.0, 184.0)
image=camera.getImage()
image.getPixel(x,y) # Um, row/column transposition?!
corrected=wb(camera.getImage(), grey_sample)
corrected.getPixel(x,y)

# How fast (slow!) is it?:

while True:
	wb(camera.getImage(), grey_sample).show()

# And with the undistortion?
while True:
	wb(camera.getImageUndistort(), grey_sample).show()

# And at reduced resolution?
while True:
	wb(camera.getImageUndistort().scale(0.25), grey_sample).show()



# And now, how to sample a bunch of pixels to assist in setting the white balance.
# To get the pixel colour at clicked position:
# Probably output in the same format as Camera.live():
# coord: (225,264), color: (158.0, 164.0, 184.0)

# NOTE: Display.mouseLeft returns the current state of the button, whereas Display.leftButtonDownPosition() returns None unless the button was only JUST pressed. We want Display.mouseX and Display.mouseY instead, I think.

# TODO: make this a function...

display = Display(resolution = (160, 120))
camera = Camera(prop_set={'width':320, 'height':240})
#camera=Camera()
camera.loadCalibration('default')
camera.getCameraMatrix()
prev_mouse_state = False
sample_pixels = []
while display.isNotDone():
	image = camera.getImage().scale(0.5)
	image.save(display)
	if display.mouseLeft:
		x = display.mouseX
		y = display.mouseY
		if not prev_mouse_state:
			# Button just pressed - initialise new list:
			sample_pixels = []
			#print(sample_pixels)
		colour_sample = image.getPixel(x,y)
		# Indicate the point being sampled:
		image.drawCircle((x,y),rad=5,color=Color.VIOLET,thickness=1)
		image.save(display)
		print(str(x) + ', ' + str(y) + ': ' + str(colour_sample))
		sample_pixels.append(colour_sample)
		prev_mouse_state = True
	else:
		if prev_mouse_state:
			# Button just released:
			# Um, how to take the mean of a list of tuples?
			mean_sample = tuple(map(lambda y: sum(y) / float(len(y)), zip(*sample_pixels)))
			print('mean grey sample: ' + str(mean_sample))
		prev_mouse_state = False



grey_sample = (97.62295081967213, 61.47540983606557, 34.90163934426229)
grey_sample = (170.66666666666666, 145.76666666666668, 97.23333333333333)

# Now we can grab corrected images...

while True:
	wb(camera.getImageUndistort().scale(0.25), grey_sample).show()


drawPaletteColors()

--


https://github.com/mn416/QPULib

